{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651c7782",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafb253-d8e4-456f-ad25-28b11d439ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L2\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import Precision, Recall\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from keras.layers import LSTM, Dense, Dropout,MaxPooling1D,Flatten,Conv1D, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7c7b1",
   "metadata": {},
   "source": [
    "# Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad109407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(model_name,model,X_test,y_test,show=False,OurDataset=True):\n",
    "    y_test_original = np.argmax(y_test, axis=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    predicted_label_indices = np.argmax(y_pred, axis=1) # get the index of the highest probability for each sample\n",
    "    # predicted_label_indices\n",
    "    cm = confusion_matrix(y_test_original, predicted_label_indices)\n",
    "    target_names=[]\n",
    "    if OurDataset:\n",
    "        target_names=['Bad-Double-Arm-Ball','Bad-Flamingo-Movement','Bad-Flamingo-Stand','Bad-Side-Leg-Raise-Movement','Bad-Single-Leg-Standing','Bad-Squatting','Bad-Tummy-Twist',\n",
    "                    'Good-Double-Arm-Ball','Good-Flamingo-Movement','Good-Flamingo-Stand','Good-Side-Leg-Raise-Movement','Good-Single-Leg-Standing','Good-Squatting','Good-Tummy-Twist']\n",
    "    else:\n",
    "        target_names=['deep squat', 'hurdle step', 'inline lunge', 'side lunge', 'sit to stand',\n",
    "                    'standing active straight leg raise','standing shoulder abduction', 'standing shoulder extension', 'standing shoulder internal-external rotation', 'standing shoulder scaption',\n",
    "                    'incorrect deep squat', 'incorrect hurdle step', 'incorrect inline lunge', 'incorrect side lunge', 'incorrect sit to stand',\n",
    "                    'incorrect standing active straight leg raise','incorrect standing shoulder abduction', 'incorrect standing shoulder extension', 'incorrect standing shoulder internal-external rotation', 'incorrect standing shoulder scaption']\n",
    "    labels = target_names\n",
    "    sns.set(font_scale=2.5)  # Adjust the font size if necessary\n",
    "    plt.figure(figsize=(32, 32))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - ' + model_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./Confusion Matrices/'+model_name+'.png')\n",
    "    if show == True:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def ReadOneData(DropColumn,input_directory):\n",
    "    data = pd.read_csv(input_directory)\n",
    "    x=data.drop(DropColumn, axis=1).values\n",
    "    y=data[DropColumn].values\n",
    "    return x,y\n",
    "\n",
    "def ReadThreeData(DropColumn,input_directory):\n",
    "    x = []\n",
    "    y = []\n",
    "    for file_name in os.listdir(input_directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            input_file_path = os.path.join(input_directory, file_name)\n",
    "            data = pd.read_csv(input_file_path)\n",
    "            last_x = normalize(data.drop(DropColumn, axis=1).values).astype('float16')\n",
    "            last_y = data[DropColumn].values[0]\n",
    "            x.append(last_x)\n",
    "            y.append(last_y)\n",
    "    return x, y\n",
    "\n",
    "def normalize(X):\n",
    "    sc = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_normalized = sc.fit_transform(X)\n",
    "    return X_normalized\n",
    "\n",
    "def reshapeData(X, time_steps, no_features):\n",
    "    X = np.reshape(X, (X.shape[0], no_features, time_steps))\n",
    "    return X\n",
    "\n",
    "def encodeLabels(y):\n",
    "    label_encoder = LabelEncoder()\n",
    "    Y_train_labeled = label_encoder.fit_transform(y)\n",
    "    unique = np.unique(Y_train_labeled)\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "    Y_train_encoded = onehot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "    return unique, Y_train_encoded\n",
    "\n",
    "def saveModel(model_name, model):\n",
    "    models_folder = './Models/'\n",
    "    date = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    savepath = f'{models_folder}{model_name}-{date}.h5'\n",
    "    model.save(savepath)\n",
    "    return savepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21220a32",
   "metadata": {},
   "source": [
    "# Models architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_Model(no_features,timesteps,no_classes):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=256, input_shape=(timesteps,no_features), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(units=no_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate= 0.0012)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), F1Score(num_classes=no_classes,name='f1')], optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def BILSTM_Model(no_features,timesteps,no_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=128, return_sequences=True), input_shape=(timesteps,no_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(units=no_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0012)\n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), F1Score(num_classes=no_classes,name='f1')], optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def LSTM_Model(no_features,timesteps,no_classes):\n",
    "    lstm_units= 256\n",
    "    dropout_rate= 0.2\n",
    "    dense_units= 512\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True,input_shape=(timesteps,no_features)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=no_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate= 0.0012)\n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), F1Score(num_classes=no_classes,name='f1')],optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def CNN_LSTM_Model(no_features,timesteps, no_classes):\n",
    "    model = Sequential()\n",
    "    conv_filters= 128\n",
    "    kernel_size= 8\n",
    "    lstm_units= 256\n",
    "    dropout_rate= 0.2\n",
    "    regularizer_strength= 0.00279\n",
    "    dense_layers= 2\n",
    "    dense_units= 525\n",
    "    num_conv_layers= 2\n",
    "    learning_rate= 0.0012\n",
    "    for _ in range(num_conv_layers):\n",
    "        conv_layer = Conv1D(filters=conv_filters, kernel_size=kernel_size, activation='relu', input_shape=(timesteps,no_features))\n",
    "        conv_layer.kernel_regularizer = keras.regularizers.l2(regularizer_strength) \n",
    "        conv_layer.bias_regularizer = L2(regularizer_strength)\n",
    "        model.add(conv_layer)\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True,input_shape=(timesteps,no_features)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    for _ in range(dense_layers):\n",
    "        model.add(Dense(units=dense_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=no_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), F1Score(num_classes=no_classes,name='f1')])\n",
    "    return model\n",
    "\n",
    "def CNN_GRU_Model(no_features,timesteps, no_classes):\n",
    "    model = Sequential()\n",
    "    conv_filters= 128\n",
    "    kernel_size= 8\n",
    "    dropout_rate= 0.2\n",
    "    regularizer_strength= 0.0001\n",
    "    num_conv_layers= 2\n",
    "    learning_rate= 0.0001\n",
    "    for _ in range(num_conv_layers):\n",
    "        conv_layer = Conv1D(filters=conv_filters, kernel_size=kernel_size, activation='relu', input_shape=(timesteps,no_features))\n",
    "        conv_layer.kernel_regularizer = keras.regularizers.l2(regularizer_strength) \n",
    "        conv_layer.bias_regularizer=L2(regularizer_strength)\n",
    "        model.add(conv_layer)\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(GRU(units=512, input_shape=(timesteps,no_features), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=no_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), F1Score(num_classes=no_classes,name='f1')])\n",
    "    return model\n",
    "\n",
    "def ModelSummary(no_features, timesteps, no_classes, Dim):\n",
    "    model = GRU_Model(no_features, timesteps, no_classes)\n",
    "    plot_model(model, to_file=f'../Documents/GRU_Model{Dim}.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    model = BILSTM_Model(no_features, timesteps, no_classes)\n",
    "    plot_model(model, to_file=f'../Documents/BILSTM_Model{Dim}.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    model = LSTM_Model(no_features, timesteps, no_classes)\n",
    "    plot_model(model, to_file=f'../Documents/LSTM_Model{Dim}.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    model = CNN_LSTM_Model(no_features, timesteps, no_classes)\n",
    "    plot_model(model, to_file=f'../Documents/CNN_LSTM_Model{Dim}.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    model = CNN_GRU_Model(no_features, timesteps, no_classes)\n",
    "    plot_model(model, to_file=f'../Documents/CNN_GRU_Model{Dim}.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b6c1d",
   "metadata": {},
   "source": [
    "# Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ca8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(X,y,no_features,time_steps,no_classes,epochs,batch_size,Dim,IsOur=True):\n",
    "    #Train Test Splitting\n",
    "    All_X_train, X_test, All_y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    #Train Validation Splitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(All_X_train, All_y_train, test_size=0.2, random_state=42)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    if Dim!=3:\n",
    "        #Reshaping Data\n",
    "        X_train = reshapeData(X_train,time_steps,no_features)\n",
    "        X_valid = reshapeData(X_valid,time_steps,no_features)\n",
    "        X_test = reshapeData(X_test,time_steps,no_features)\n",
    "    # LSTM model\n",
    "    model = LSTM_Model(time_steps,no_features, no_classes)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),callbacks=[early_stopping])\n",
    "    accuracy = model.evaluate(X_valid, y_valid)[1]* 100\n",
    "    model_name = f'LSTM-{Dim}D-{accuracy:.2f}%' if IsOur else f'UIPRMD-LSTM-{Dim}D-{accuracy:.2f}%'\n",
    "    saveModel(model_name,model)\n",
    "    ConfusionMatrix(model_name,model,X_test,y_test) if IsOur else ConfusionMatrix(model_name,model,X_test,y_test,OurDataset=False)\n",
    "    model.reset_states()\n",
    "    \n",
    "    #CNN-LSTM model\n",
    "    model = CNN_LSTM_Model(time_steps,no_features, no_classes)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),callbacks=[early_stopping])\n",
    "    accuracy = model.evaluate(X_valid, y_valid)[1]* 100\n",
    "    model_name = f'CNN-LSTM-{Dim}D-{accuracy:.2f}%' if IsOur else f'UIPRMD-CNN-LSTM-{Dim}D-{accuracy:.2f}%'\n",
    "    saveModel(model_name,model)\n",
    "    ConfusionMatrix(model_name,model,X_test,y_test) if IsOur else ConfusionMatrix(model_name,model,X_test,y_test,OurDataset=False)\n",
    "    model.reset_states()\n",
    "    \n",
    "    #GRU model\n",
    "    model = GRU_Model(time_steps,no_features, no_classes)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),callbacks=[early_stopping])\n",
    "    accuracy = model.evaluate(X_valid, y_valid)[1]* 100\n",
    "    model_name = f'GRU-{Dim}D-{accuracy:.2f}%' if IsOur else f'UIPRMD-GRU-{Dim}D-{accuracy:.2f}%'\n",
    "    saveModel(model_name,model)\n",
    "    ConfusionMatrix(model_name,model,X_test,y_test) if IsOur else ConfusionMatrix(model_name,model,X_test,y_test,OurDataset=False)\n",
    "    model.reset_states()\n",
    "    \n",
    "    #CNN-GRU model\n",
    "    model = CNN_GRU_Model(time_steps,no_features, no_classes)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),callbacks=[early_stopping])\n",
    "    accuracy = model.evaluate(X_valid, y_valid)[1]* 100\n",
    "    model_name = f'CNN-GRU-{Dim}D-{accuracy:.2f}%' if IsOur else f'UIPRMD-CNN-GRU-{Dim}D-{accuracy:.2f}%'\n",
    "    saveModel(model_name,model)\n",
    "    ConfusionMatrix(model_name,model,X_test,y_test) if IsOur else ConfusionMatrix(model_name,model,X_test,y_test,OurDataset=False)\n",
    "    model.reset_states()\n",
    "    \n",
    "    #BILSTM model\n",
    "    model = BILSTM_Model(time_steps,no_features, no_classes)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),callbacks=[early_stopping])\n",
    "    accuracy = model.evaluate(X_valid, y_valid)[1]* 100\n",
    "    model_name = f'BILSTM-{Dim}D-{accuracy:.2f}%' if IsOur else f'UIPRMD-BILSTM-{Dim}D-{accuracy:.2f}%'\n",
    "    saveModel(model_name,model)\n",
    "    ConfusionMatrix(model_name,model,X_test,y_test) if IsOur else ConfusionMatrix(model_name,model,X_test,y_test,OurDataset=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f001bc",
   "metadata": {},
   "source": [
    "# 1D Run on Collected DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c55ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Run():\n",
    "#     DropColumn='Label'\n",
    "#     input_directory = './CSVS/CSV_FeatureEngineering.csv'\n",
    "#     x, y=ReadOneData(DropColumn,input_directory)\n",
    "#     x=normalize(x)\n",
    "#     unique,y=encodeLabels(y)\n",
    "#     no_features = x.shape[1]\n",
    "#     no_classes = len(unique)\n",
    "#     timesteps = 1\n",
    "#     epochs=50\n",
    "#     batch_size=41\n",
    "#     ModelSummary(timesteps, no_features, no_classes, 1)\n",
    "#     Train(x, y, no_features, timesteps, no_classes, epochs, batch_size, 1)\n",
    "# Run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268564d8-885d-4b52-a8aa-40330adc0951",
   "metadata": {},
   "source": [
    "# 1D Run on UI_PRMD DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1eb08-b33a-4a17-ba0a-f789dc5e0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Run():\n",
    "#     DropColumn='Label'\n",
    "#     input_directory='./CSVS/CSV_STD.csv'\n",
    "#     x, y=ReadOneData(DropColumn,input_directory)\n",
    "#     unique,y=encodeLabels(y)\n",
    "#     no_features = x.shape[1]\n",
    "#     no_classes = len(unique)\n",
    "#     time_steps = 1\n",
    "#     epochs=50\n",
    "#     batch_size=100\n",
    "#     ModelSummary(timesteps, no_features, no_classes, 1)\n",
    "#     Train(x, y, no_features, time_steps, no_classes, epochs, batch_size, 1,False)\n",
    "# Run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57018184",
   "metadata": {},
   "source": [
    "# 3D Run on Collected DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c14b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Run():\n",
    "#     DropColumn='Label'\n",
    "#     input_directory = '../Padded-CSVS/'\n",
    "#     x, y=ReadThreeData(DropColumn,input_directory)\n",
    "#     x = np.array(x)\n",
    "#     y = np.array(y)\n",
    "#     unique,y=encodeLabels(y)\n",
    "#     no_features = x.shape[1]\n",
    "#     time_steps = x.shape[2]\n",
    "#     no_classes = len(unique)\n",
    "#     print(x.shape)\n",
    "#     epochs=50\n",
    "#     batch_size=30\n",
    "#     ModelSummary(time_steps, no_features, no_classes, 3)\n",
    "#     Train(x,y,no_features,time_steps,no_classes,epochs,batch_size,3)\n",
    "# Run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
